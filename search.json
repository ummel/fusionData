[{"path":"https://ummel.github.io/fusionData/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kevin Ummel. Author, maintainer.","code":""},{"path":"https://ummel.github.io/fusionData/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ummel K (2023). fusionData: Data backend fusionACS platform. R package version 0.3.0.","code":"@Manual{,   title = {fusionData: Data backend for fusionACS platform},   author = {Kevin Ummel},   year = {2023},   note = {R package version 0.3.0}, }"},{"path":"https://ummel.github.io/fusionData/index.html","id":"fusiondata","dir":"","previous_headings":"","what":"Data backend for fusionACS platform","title":"Data backend for fusionACS platform","text":"Kevin Ummel (ummel@berkeley.edu) Overview Setup install Usage structure Ingest survey data Document variables Harmonize variables Compile spatial data Prepare fusion Make rain","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Data backend for fusionACS platform","text":"fusionData used create manage data inputs underpinning larger fusionACS platform. facilitates number steps overall fusionACS workflow: Ingest: Process raw survey data using standard approach formatting. Document: Document survey variables compile “universal” data dictionary. Harmonize: Harmonize variables “donor” surveys American Community Survey (ACS). Compile spatial data: Compile data multiple spatial datasets merging survey microdata. Prepare fusion: Prepare donor ACS/recipient microdata inputs passed fusionModel package.","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"setup-and-install","dir":"","previous_headings":"","what":"Setup and install","title":"Data backend for fusionACS platform","text":"fusionData master branch can cloned project directory local machine using RStudio instructions. Use following setup parameters: prompted enter Github username password. repository cloned local project directory, can install load package . may prompted install dependencies. *Note: use multi-factor authentication Github credentials, need enable SSH key, need use git@github.com:ummel/fusionData.git Repository URL setup parameters. may prompted enter password Google Drive account storing remote files. username: fusionACSdata password: fusethis!! full functionality, necessary download remotely-stored processed survey microdata processed spatial data files. following section (“Structure usage”) detail associated reasoning. See ?getSurveyProcessed ?getGeoProcessed well. get running, ’ll need call following commands. download take minutes. files automatically placed appropriate sub-directories /fusionData, directories created necessary. successful download, fusionData “system” ready go.","code":"Repository URL: https://github.com/ummel/fusionData Project directory name: fusionData # Install the fusionData package locally devtools::install()  # Load fusionData package library(fusionData) # Download all remote processed survey microdata files getSurveyProcessed(survey = \"all\")  # Download only the essential remote spatial data files getGeoProcessed(dataset = \"essential\")"},{"path":"https://ummel.github.io/fusionData/index.html","id":"usage-and-structure","dir":"","previous_headings":"","what":"Usage and structure","title":"Data backend for fusionACS platform","text":"Although fusionData structured (loadable) R package, better think code data repository shared continuously modified authorized users. fusionData expected grow time new surveys spatial datasets – code needed process manipulate – added. fusionData public. modify code files local /fusionData project directory, need commit push changes Github repository accessible users. addition, good practice pull latest version repository Github prior making modifications. way, know working latest shared version. Since Github places limits file/repository size, decided store certain data files “remotely” – , outside Github repository. Specifically, lowest-level “raw” data inputs associated “processed” versions data (details ). time, expected types data files become quite large aggregate. remotely-stored “raw” “processed” data files integral overall fusionData “system”, present Github repository . Instead, remote files (associated directory structure) stored Google Drive can automatically safely added user’s local fusionData folder using provided functions. remote files added, user’s local fusionData package fully functional. Remote data files rather static time. , expected user need update (re-download) remote files local fusionData directory infrequently. However, users add modify code (smaller, ancillary data files), changes pushed Github repository become subject code reviews, versioning control, accessible authorized users. short: Github repository stores code needed build document fusionData architecture. certain, infrequently-modified data files stored remotely. Users can add remote files local installation fusionData code ancillary data files pushed Github modified. Changes additions remote files likely rare, done “hand” prevent inadvertent changes. overview top-level directories fusionData repository, including Github-based “remote” elements.","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"r","dir":"","previous_headings":"Usage and structure","what":"/R","title":"Data backend for fusionACS platform","text":".R scripts defining functions “fusionData things”. exported.","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"data","dir":"","previous_headings":"Usage and structure","what":"/data","title":"Data backend for fusionACS platform","text":"Shared, package-wide .rda data files. Loadable via data(), usual R packages.","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"data-raw","dir":"","previous_headings":"Usage and structure","what":"/data-raw","title":"Data backend for fusionACS platform","text":".R scripts needed create package-wide .rda objects /data, usual R packages.","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"man","dir":"","previous_headings":"Usage and structure","what":"/man","title":"Data backend for fusionACS platform","text":"Documentation (.e. “manual”) functions /R data /data, usual R packages.","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"universe","dir":"","previous_headings":"Usage and structure","what":"/universe","title":"Data backend for fusionACS platform","text":"Directory “Universal Survey Dictionary” Shiny app. app can run calling universe().","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"harmony","dir":"","previous_headings":"Usage and structure","what":"/harmony","title":"Data backend for fusionACS platform","text":"Directory “Survey Harmonization Tool” Shiny app. app can run calling harmony().","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"survey-processed","dir":"","previous_headings":"Usage and structure","what":"/survey-processed","title":"Data backend for fusionACS platform","text":"Contains processed survey data associated code. Subdirectories refer specific surveys vintages. Example: /survey-processed/RECS/2015 Github repository version /survey-processed contains two kinds files: Custom .R scripts transform raw survey microdata (located /survey-raw) “processed” versions adhere certain requirements, structure, naming conventions. Example: /survey-processed/RECS/2015/RECS_2015_H_processed.R “Dictionary” files (.rds) contain standardized metadata variable descriptions particular survey. Example: /survey-processed/RECS/2015/RECS_2015_H_dictionary.rds /survey-processed also includes .fst files containing processed microdata . files stored remotely can added user’s local fusionData directory calling getSurveyProcessed(). example, .fst file /survey-processed/RECS/2015/RECS_2015_H_processed.fst contains processed, household-level microdata 2015 RECS. code creates file found /survey-processed/RECS/2015/RECS_2015_H_processed.R. .R file part Github repository (see ), .fst file stored remotely. Use .fst files allows data read quickly disk, part full. Functions fusionData package take advantage .","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"survey-raw","dir":"","previous_headings":"Usage and structure","what":"/survey-raw","title":"Data backend for fusionACS platform","text":"remote directory (.e. present Github repository) containing raw survey data files. Subdirectories refer specific surveys vintages. Example: /survey-raw/RECS/2015 /survey-raw can downloaded added user’s local fusionData directory calling getSurveyRaw(). However, practice, reason user store raw survey data locally unless survey actively processing editing. processed version survey (*_processed.fst) stable uploaded remote Google Drive, users can access use processed version without ever needing download look original/raw data.","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"geo-processed","dir":"","previous_headings":"Usage and structure","what":"/geo-processed","title":"Data backend for fusionACS platform","text":"Contains processed spatial data associated code. Subdirectories refer specific spatial datasets. Example: /geo-processed/EPA-SLD Github repository version /geo-processed contains following kinds files: Custom .R scripts transform raw spatial data (located /geo-raw) processed .rds files meet certain requirements. Example: /geo-processed/EPA-SLD/epa-sld_v3_processed.R /geo-processed also includes .rds files containing processed spatial data . files stored remotely can added user’s local fusionData directory calling getGeoProcessed(). example, .rds file /geo-processed/EPA-SLD/epa-sld_v3_processed.rds contains processed spatial variables version 3 EPA’s Smart Location Database (SLD). code creates file found /geo-processed/EPA-SLD/epa-sld_v3_processed.R. .R file part Github repository (see ), .rds file stored remotely. Importantly, /geo-processed remote content also includes three “essential” spatial data files , practice, users need perform data fusion locally. files roles described detail later . geo_predictors.fst concordance/geo_concordance.fst users modifying adding spatial datasets, sufficient call getGeoProcessed(dataset = \"essential\") load essential “geo” files.","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"geo-raw","dir":"","previous_headings":"Usage and structure","what":"/geo-raw","title":"Data backend for fusionACS platform","text":"remote directory (.e. present Github repository) containing raw spatial data files. Subdirectories refer specific spatial datasets. Example: /geo-raw/EPA-SLD /geo-raw can downloaded added user’s local fusionData directory calling getGeoRaw(). However, practice, reason user store raw spatial data locally unless spatial dataset actively processing editing.","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"production","dir":"","previous_headings":"Usage and structure","what":"/production","title":"Data backend for fusionACS platform","text":"Directory containing code possibly data “production” fusion runs. likely temporary inclusion. additional fusion results produced, create structured way storing organizing production data outputs.","code":""},{"path":"https://ummel.github.io/fusionData/index.html","id":"ingest-survey-data","dir":"","previous_headings":"","what":"Ingest survey data","title":"Data backend for fusionACS platform","text":"“Ingesting” survey requires transforming raw survey data “processed” (.e. standardized) microdata files meet certain requirements. fusionData codebase depends processed microdata recognizable structure features. ingestion process survey documented defined .R script (possibly multiple scripts) must written manually. goal produce data.frame containing microdata observations (ideally) meet following conditions: Contains many observations variables possible. Variable names descriptions taken official codebook, possibly modified clarity. Official variable names coerced lower-case alphanumeric, possibly using single underscores. Codes used raw data replaced descriptive labels codebook; e.g. integer values replaced associated factor levels. “valid blanks” raw data set plausible values; NA’s often actual zeros knowable value based question structure. “invalid blanks” missing values raw data imputed; generic imputation function provided purpose. Ordered factors used defined whenever possible (opposed unordered). Standard column names used unique household identifiers (e.g. “acs_2019_hid”); person-level microdata within-household person identifier (integer) always “pid”. Standard column names used observation weights; “weight” primary weighting variable “rep_1”, etc. replicate weights. Variables identifying respondent location consistent defined geo-processed/concordance/geo_concordance.fst. Let’s look variables processed RECS 2015 microdata get sense preferred output looks like. Note file name includes _H_ identifier, indicating microdata question household-level. Surveys include household person-level respondent information two files – “H” “P” microdata. RECS household (“H”) microdata. Notice household ID variable standardized name (“recs_2015_hid”), observation weights column (“weight”) first 96 replicate weights (“rep_1”). microdata consisted person-level observations nested within households (e.g. ACS), additional “pid” integer variable uniquely identify person within household. case “sizeofgarage” (original variable name RECS), raw data contained NA’s (valid “skips”) households without garage. blanks replaced intelligible label (“garage”). addition, “sizeofgarage” classed ordered factor, since labels natural ordering. variable “recs_iecc_zone” tells us something respondent’s location (IECC climate zone). spatially-referenced variables defined named consistent variables geo-processed/concordance/geo_concordance.fst file. allows subsequent operations intelligently impute respondent location prior fusion. details spatial data location imputation can found subsequent sections. important location variables donor survey precisely consistent defined geo_concordance.fst. latter file can modified, necessary, add new location variables allow concordance. strictly necessary donor survey include variable (set variables) provide maximum information respondent location. example, survey contained “county” variable, reason include “state” – though code shouldn’t break included. surveys (like RECS) complicated combination location variables collectively define respondent location spatial intersection. fusionData’s code base automatically handles , provided location variables consistent (.e. name levels) donor microdata geo_concordance.fst file. need specify variables location variables; determined automatically looking overlap column names geo_concordance.fst file. can see , exactly, raw survey data transformed viewing associated code /survey-processed/RECS/2015/RECS_2015_H_processed.R. Given variety survey data structures conventions, strict procedure .R file written. However, common steps tools likely applicable surveys. RECS_2015_H_processed.R script good “template” regard, since includes many common operations – including imputation NA’s using provided imputeMissing() function. RECS 2015 comparatively simple microdata documentation structure: household-level microdata single .csv file associated .xls codebook. surveys require complex steps assemble necessary microdata. limit number nature .R files can used ingest survey. multiple .R files used, file names include two-digit sequence front indicate order scripts employed (01*.R, 02*.R, etc.). .R files include liberal use comments help others understand code later. Good practice comments explain piece code included, just . cases, .R script eventually saves _processed.fst microdata file disk must include use labelled::set_variable_labels assign variable descriptions (ideally, taken official codebook) column. script must call createDictionary() function create save standardized “dictionary.rds” file. createDictionary() uses assigned variable descriptions information microdata build dictionary standardized way. can see end RECS_2015_H_processed.R: resulting dictionary file RECS 2015. practice, reason typical user ever open survey’s dictionary file. preferred much useful way explore survey metadata variable descriptions via universe() function described next section. August 2021, American Community Survey (ACS) microdata ingested 2015 2019. expected additional vintages eventually added allow temporal alignment vintages donor surveys. .R scripts used process 2015 2019 ACS microdata can serve templates ingesting vintages.","code":"recs <- fst::read_fst(\"survey-processed/RECS/2015/RECS_2015_H_processed.fst\") head(select(recs, recs_2015_hid, weight, rep_1, sizeofgarage, recs_iecc_zone)) recs_2015_hid weight rep_1   sizeofgarage           recs_iecc_zone 1         10001  12090 16560 Two-car garage IECC climate zones 3B-4B 2         10002  14400 21500      No garage IECC climate zones 1A-2A 3         10003  23330 12300      No garage     IECC climate zone 3A 4         10004  12170 18550 Two-car garage     IECC climate zone 4A 5         10005  16720  8080 One-car garage     IECC climate zone 5A 6         10006  26060 37000      No garage IECC climate zones 6A-6B class(recs$sizeofgarage) [1] \"ordered\" \"factor\" levels(recs$sizeofgarage) [1] \"No garage\"                \"One-car garage\"           [3] \"Two-car garage\"           \"Three-or-more-car garage\" recs.dictionary <- readRDS(\"survey-processed/RECS/2015/RECS_2015_H_dictionary.rds\") head(recs.dictionary) # A tibble: 6 × 8   survey vintage respondent variable  description             values type      n   <chr>  <chr>   <chr>      <chr>     <chr>                   <chr>  <chr> <int> 1 RECS   2015    H          adqinsul  Level of insulation     [Not … ord    5686 2 RECS   2015    H          agecdryer Age of clothes dryer    [No c… ord    5686 3 RECS   2015    H          agecenac  Age of central air con… [No c… ord    5686 4 RECS   2015    H          agecwash  Age of clothes washer   [No c… ord    5686 5 RECS   2015    H          agedw     Age of dishwasher       [No d… ord    5686 6 RECS   2015    H          agefrzr   Age of most-used freez… [No f… ord    5686"},{"path":"https://ummel.github.io/fusionData/index.html","id":"document-variables","dir":"","previous_headings":"","what":"Document variables","title":"Data backend for fusionACS platform","text":"previous section showed survey’s “dictionary.rds” file(s) created. Whenever dictionary file added updated, necessary run compileDictionary() function compile fusionData’s individual survey dictionaries single “universal” dictionary. usage straightforward: console output reveals, compileDictionary() updates two files: data/dictionary.rda data/surveys.rda. files part Github repository used “Universal Survey Dictionary” “Survey Harmonization Tool” Shiny apps part fusionData. “Universal Survey Dictionary” Shiny app can accessed following call: open app browser window. tool allows “universe” available variables – across ingested surveys – sorted searched. user consult universal dictionary initial ingestion new survey, effective way identify variables need additional editing. may eventually make app public potential fusionACS users can browse universe available fusion variables.","code":"compileDictionary() # Open \"Universal Survey Dictionary\" Shiny app universe()"},{"path":"https://ummel.github.io/fusionData/index.html","id":"harmonize-variables","dir":"","previous_headings":"","what":"Harmonize variables","title":"Data backend for fusionACS platform","text":"donor survey successfully ingested documented, possible start thinking fuse survey ACS. statistical linchpin fusion process set “harmonized” variables common donor survey ACS. Identifying conceptually similar variables across surveys determining can modified measure similar concepts one important steps process. also potentially time-consuming error-prone. “Survey Harmonization Tool” created make process easier safer. Shiny app makes easier detect, specify, save “harmonies” constructed variables donor surveys variables ACS. app launches browser window following call: present, harmony() app allows specification harmonies non-ACS donor survey specific ACS vintage (e.g. harmonizing 2015 RECS 2015 ACS). Construction harmony generally follows steps: Select donor survey vintage. Select recipient ACS vintage. Select “Donor variable” drop list. list searchable help locate variables associated certain words. Select “ACS variable” use “side” harmony. factor variables, edit “Group” columns spreadsheet objects create maximum-resolution harmony two variables. can see “live” outcome specified harmonization strategy table bottom page. continuous variables, additional modification needed long two variables measure similar concepts. harmony specified like, click “Submit harmony”. button becomes available click minimal safety checks passed valid harmony. user clicks “Submit harmony”, currently-specified harmony (defined selected variables settings) saved disk. Specifically, details particular harmony added appropriate .R “harmony file” located /harmony/harmonies. example, file describing harmonize RECS 2015 ACS 2015 variables RECS_2015__ACS_2015.R. receive pop-message indicating harmony successfully added local .R harmony file (created, necessary). can confirm harmony added selecting “View harmonies” panel. Probably easiest way become expert app view existing harmonies ’ve already constructed RECS CEI. show settings used give sense used. Additional details regarding “advanced” settings examples. may seem convoluted first. understand fields , becomes quite easy, fast, (almost) fun construct harmonies. Bin breakpoints Bin breakpoints field used specify continuous variable “binned” turn categorical variable – usually allow harmonization factor variable survey. useful identical concept measured continuous scale one survey (e.g. income dollars) factor variable survey (e.g. income range). Example: Select “moneypy” RECS 2015 see ACS “hincp” binned create harmony. Adjustment Adjustment field provides powerful way modify adjust variables accommodate non-standard harmonies. Text Adjustment field passed -dplyr::mutate() call within harmonize() modifies associated variable prior manipulation. text passed mutate() call can utilize variables microdata. quite powerful allows complicated harmonies accommodated. Example: Select “vehq” CEI 2015-2019. case, “vehq” (owned vehicles) “vehql” (leased vehicles) variables CEI – continuous – added together specifying “vehq + vehql” Adjustment field. result binned create harmony ACS “veh” variable, factor variable referring available vehicles, whether owned leased. Household aggregator Sometimes possible create harmony household-level (“H”) donor variable person-level (“P”) ACS variable, provided latter aggregated household level. cases, “Household aggregator” field tells harmonize() aggregate summarize person-level ACS variable within household. field applicable donor variable household variable selected ACS variable person-level (person-level donor variables can always harmonized directly person-level ACS variables). Simple example: Select “hhage” RECS 2015 (Respondent/head--household age). ACS “agep” variable can used create harmony, person-level variable. setting Household aggregator field “reference” instruct harmonize() use “reference person” value “agep” create household-level variable analogous “hhage”. Advanced example: Select “numchild” RECS 2015 (Number household members age 17 younger). ACS “agep” variable can used create harmony. Bin breakpoints used re-assign household member “agep” value 1 less 18 0 18 (see “Group” column associated spreadsheet). Household aggregator field set “sum” instruct harmonize() sum values household level, creates harmony “numchild”. advanced example: Select “as_comp1” CEI 2015-2019 (Number males age 16 ). , ACS “agep” variable can used create harmony (“numchild”), need additionally restrict harmony males . done using Adjustment field first set “agep” 0 females, bin result, sum household level. Comments Comments field used leave helpful information harmony constructed . harmony makes use one “advanced” settings probably comment explaining rationale. harmony file can dget-d return list lists, element defines harmony. Like one, defining harmony “fuelheat” variable RECS “hfl” variable ACS. list object contains information necessary construct RECS ACS microdata containing new variable called “fuelheat__hfl”; .e. harmonized version two associated heating fuel variables. precisely harmonize() function – typically called prepare() explained – using harmonies available specified harmony file. Note harmonized variables always indicated double-underscore (“__“). Using harmony() app manually define harmonies letting harmonize() take care subsequent data manipulation makes construction harmonized microdata easier, faster, much safer. generally advisable use harmonize() app create edit harmonies. also possible manually edit .R harmony files, necessary, careful. users eventually find constructing harmonies via app , result, modifying local version .R harmony files. means must commit push changes show Github repository – become available others use. also means important pull recent version repository begin working fusionData. Otherwise, risk duplicating efforts someone else /failing make use recent version harmony () files.","code":"# Open \"Survey Harmonization Tool\" Shiny app harmony() fuelheat__hfl = list( RECS = list( groups = 1:7, levels = c(\"Do not use space heating\", \"Electricity\", \"Fuel oil/kerosene\", \"Natural gas from underground pipes\", \"Propane (bottled gas)\", \"Some other fuel\", \"Wood (cordwood or pellets)\"), breaks = \"\", adj = \"\"), ACS = list( groups = c(5, 6, 2, 3, 1, 6, 6, 4, 7), levels = c(\"Bottled, tank, or LP gas\", \"Coal or coke\", \"Electricity\", \"Fuel oil, kerosene, etc.\", \"No fuel used\", \"Other fuel\", \"Solar energy\", \"Utility gas\", \"Wood\"), breaks = \"\", adj = \"\"), ordered = FALSE, comment = \"\", modified = \"2021-07-03 12:10:17\"),"},{"path":"https://ummel.github.io/fusionData/index.html","id":"compile-spatial-data","dir":"","previous_headings":"","what":"Compile spatial data","title":"Data backend for fusionACS platform","text":"fusionData allows spatially-referenced data merged survey microdata, thereby expanding set potential predictor variables available fusion process. geographic “unit analysis” case consists PUMA’s, observed ACS households can imputed donor households. Ingestion spatial datasets generally less onerous survey data; fewer requirements processed data must meet. general strategy look familiar: Raw spatial data stored /geo-raw. raw data transformed “*_processed.rds” file stored /geo-processed. associated .R file stored location. processed spatial .rds file two hard requirements must meet. must contain “vintage” column indicating time period observation. vintage can year, year range (“2015-2016”), special value “always”. “always” value indicates measurement time-invariant (e.g. long-term climate “normal”). must contain column (columns) whose name values also found geo_concordance.fst file. columns define location measurement – via geo_concordance.fst file – mapped PUMA’s. Ordered factor variables classed ; categorical variables can character. (currently) necessary document variables, name certain way, create dictionary. Let’s look example. irs object contains processed spatial data constructed IRS Statistics Income (SOI) zip code tax return data 2018. underlying raw data stored remotely /geo-raw/IRS-SOI/2018. script used create “processed.rds” file available . “zcta10” column indicates Zip Code Tabulation Area (circa 2010) associated observation. “zcta10” variable also found “geo_concordance.fst” file, contains information link geographic units PUMA’s. creation relies heavily data Missouri Census Data Center’s Geocorr engine. information link zip codes PUMA’s used aggregate IRS-SOI data PUMA-level prior merging survey microdata. geo_concordance.fst file contains variety variables can used identify location observations processed spatial data file. documented Geocorr. Others added within geo-processed/concordance/geo_concordance.R file allow concordance variables found particular datasets. concordance file can expanded time necessary. cases, spatial dataset’s processed .rds file include multiple location variables used collectively achieve spatial concordance. example, spatial dataset block group observations must include columns “state”, “county10”, “tract10”, “bg10” order allow smooth merge concordance file (case EPA-SLD dataset). Unlike processed survey data, naming convention processed spatial data files quite relaxed. function compileSpatial() automatically detects compiles files /geo-processed ending “_processed.rds”. long processed spatial data file necessary suffix – meets two hard requirements mentioned – compiled geo_predictors.fst file. Whenever processed .rds file added updated, necessary run compileSpatial() update geo_predictors.fst file. geo_predictors.fst file contains variables vintages across available spatial datasets, aggregated PUMA-level preparation merging survey microdata. structure file unusual, intended worked directly. designed allow assemble() function (demonstrated ) efficiently read necessary data disk merges spatial variables particular donor recipient surveys. Consequently, unless user actively adding editing processed spatial data, “geo files” strictly necessary fusion process geo_predictors.fst geo_concordance.fst, can obtained calling getGeoProcessed(dataset = \"essential\").","code":"irs <- readRDS(\"geo-processed/IRS-SOI/IRS-SOI_2018_processed.rds\") head(irs[, 1:5]) # A tibble: 6 × 5   zcta10 vintage `Mean income per return` `Mean income per person` Mean people…¹   <chr>    <int>                    <int>                    <int>         <dbl> 1 35004     2018                    58600                    28760          2.04 2 35005     2018                    41200                    21200          1.94 3 35006     2018                    53100                    25300          2.10 4 35007     2018                    62300                    29240          2.13 5 35010     2018                    52900                    25700          2.06 6 35014     2018                    50300                    25900          1.94 # … with abbreviated variable name ¹​`Mean people per return` concordance <- fst::fst(\"geo-processed/concordance/geo_concordance.fst\") names(concordance) [1] \"puma10\"           \"puma_weight\"      \"state\"            \"state_name\"        [5] \"state_postal\"     \"county10\"         \"cousubfp10\"       \"tract10\"           [9] \"bg10\"             \"zcta10\"           \"cbsa10\"           \"cbsatype10\"       [13] \"metdiv10\"         \"csa10\"            \"sldu10\"           \"sldl10\"           [17] \"sdbest10\"         \"sdbesttype10\"     \"sldu12\"           \"sldl12\"           [21] \"ur12\"             \"ua12\"             \"cbsa13\"           \"cbsatype13\"       [25] \"metdiv13\"         \"csa13\"            \"county14\"         \"cousubfp14\"       [29] \"sldu14\"           \"sldl14\"           \"sdbest14\"         \"sdbesttype14\"     [33] \"cbsa15\"           \"cbsatype15\"       \"metdiv15\"         \"csa15\"            [37] \"sldu16\"           \"sldl16\"           \"cd111\"            \"cd113\"            [41] \"cd114\"            \"cd115\"            \"cd116\"            \"region\"           [45] \"division\"         \"recs_domain\"      \"recs_division\"    \"recs_ba_zone\"     [49] \"recs_iecc_zone\"   \"climate_division\""},{"path":"https://ummel.github.io/fusionData/index.html","id":"prepare-for-fusion","dir":"","previous_headings":"","what":"Prepare for fusion","title":"Data backend for fusionACS platform","text":"following example shows fusionData prepare() assemble() functions generate complete, consistent, harmonized microdata can passed fusionModel package fuse donor variables ACS microdata. simplest usage shown . case, requesting microdata outputs household-level allow us (subsequently) fuse RECS 2015 donor variables ACS 2015 recipient microdata. prepare() assemble() separate functions prepare() tends expensive. can usually called just (possibly saving output disk), assemble() invoked multiple times debug test different assembly options. resulting data object list containing two data frames. first slot contains “fusion ready” donor microdata. second slot contains analogous ACS recipient microdata. Notice RECS microdata variables/columns ACS data. assemble donor output includes – default – valid variables donor survey used create harmonies. latter potential candidates fusion (many case RECS). key purpose prepare() harmonize donor recipient “shared” variables. done internally harmonize() function, using variable harmonies created users via harmony() tool. case, harmonize() using RECS_2015__ACS_2015.R file harmonize donor recipient microdata. Let’s look shared variables harmonization. Notice harmonized variable values typically integers (possibly factorized); , contain intelligible labels. harmonize() maps original value/level (integer) group assignment specified relevant .R harmony file. one exception numeric variables two surveys conceptually identical included “” (automatically) converted scaled values. Since RECS ACS nationally representative surveys, distribution harmonized variables look pretty similar across two data frames. can confirm fuelheat__hfl variable, creates harmony RECS ACS heating fuel variables (“fuelheat” “hfl”, respectively). can compare proportion cases harmonized value. prepare() also calls internal function assignLocation() impute one plausible PUMA’s donor household. implicates argument controls many PUMA’s imputed donor household. Setting implicates higher results variability spatial predictors merged given household, reflecting uncertainty household located. use implicates mimics usage standard multiple imputation techniques (5 implicates typical). spatial imputation algorithm coded assignLocation() requires explanation. location variables donor microdata used identify set possible PUMA’s assignable household, initial likelihood selection proportional number housing units PUMA. However, can also exploit fact observe harmonized variables donor ACS respondents – PUMA ACS respondents known. , information harmonized variables can used alter likelihood selecting given PUMA. conceptual example: Imagine, based location variables alone, know particular donor household resident one five PUMA’s (001 005), equal number housing units. Using information alone, assign PUMA equal probability selection (call P). However, also observe household income donor ACS households. donor household high income. notice ACS microdata high income households common PUMA 001 rare four. Conceptually, information increase probability selecting PUMA 001. practice, typically observe multiple harmonized variables – categorical continuous. assignLocation() calculates Gower’s distance, using harmonized variables, derive pairwise similarity value (S) donor household random sample ACS households located within feasible set PUMA’s. calculation uses efficient gower package; even , random sampling ACS necessary make tractable. ACS household (multiple implicates > 1) randomly selected, probability selection P / S associated PUMA imputed donor household. , naive, population-based probability selection (P) modified observable similarity donor household ACS household (S). assemble() also merges spatial variables onto donor recipient microdata. Pre-compiled spatial variables (geo_predictors.fst) merged onto donor recipient microdata PUMA level, using imputed PUMA’s donor. Spatial variables indicated double-dot (“..”) variable name, analogous way harmonized variables indicated double-underscore (“__“). Let’s look variables recipient ACS microdata. string left “..” identifies spatial dataset variable comes (e.g. “irs.soi”). string right unique, syntactically-valid identifier. ’s critical specific spatial variables identifiable fusion process. pre-processing spatial datasets impose stringent naming/documentation convention (flexible design), non-nonsensical--unique names safest way identify spatial variables. “loc..*” variables refer location variables directly observed donor assignable recipient microdata basis respondent PUMA. Now let’s explore additional arguments assemble(): can request certain fusion variables passing character vector fusion.variables. input checked internally data valuid fusion candidates returned (helpful message console). can limit spatial datasets merged microdata via spatial.datasets argument. Default include available datasets, sensible cases. window argument controls wide timespan (+/- window years data vintage) tolerated merging spatial variables microdata. default (window = 0) means spatial variables merged vintage matches microdata. larger window generally mean spatial variables output cost terms temporal alignment. pca argument controls whether/principal components analysis (PCA) used reduce dimensionality spatial variables. ?prepare provides additional details concerning pca argument. Setting replicates = TRUE cause replicate observation weights returned along central/primary weight column. following shows complex (realistic) call prepare() assemble(), making use optional arguments. number observations donor microdata now higher, reflecting use implicates = 5. difference number columns RECS ACS microdata due former’s inclusion three requested fusion variables. Otherwise, data frames entirely consistent one another; assemble() performs formal checks ensure case. microdata set includes unique household identifier variable identical set harmonized survey spatial variables can exploited fusion process. specifying pca argument, numeric spatial variables collapsed smaller number components – indicated “pca..” prefix – can confirm looking recipient column names.","code":"# Prepare RECS 2015 household microdata for fusion with ACS 2015 microdata prep <- prepare(donor = \"RECS_2015\", recipient = \"ACS_2015\", respondent = \"household\") Harmonizing RECS_2015 (donor) microdata at household level Harmonizing ACS_2015 (recipient) microdata at household level Identified 124 geographic intersections in the donor... Imputing PUMA for donor observations... Assigning location variables to recipient observations... # Assemble using default options data <- assemble(prep) Identifying donor fusion variables... Adding the following fusion variables:  adqinsul, agecdryer, agecenac, agecwash, agedw, agefrzr, agerfri1, agerfri2, aircond, altfuelpev, amtmicro, appother, athome, attccool, attcheat, attic, atticfin, audit, auditchg, backup, basecool, basefin, baseheat, benother, blender, btuel, btuelahucol, btuelahuheat, btuelcdr, btuelcfan, btuelcok, btuelcol, btuelcw, btueldhum, btueldwh, btuelevapcol, btuelfrz, btuelhtbheat, btuelhtbpmp, btuelhum, btuellgt, btuelmicro, btuelnec, btuelplpmp, btuelrfg, btuelrfg1, btuelrfg2, btuelsph, btueltv1, btueltv2, btueltvrel, btuelwth, btufo, btufonec, btufosph, btufowth, btulp, btulpcdr, btulpcok, btulpnec, btulpsph, btulpwth, btung, btungcdr, btungcok, btunghtbheat, btungnec, btungplheat, btungsph, btungwth, cablesat, cdd30yr, cdd65, cdd80, cellar, cellphone, cenachp, coffee, coldma, combodvr, cooktuse, cooltype, crockpot, cufeetng, cufeetngcdr, cufeetngcok, cufeetnghtbheat, cufeetngnec, cufeetngplheat, cufeetngsph, cufeetngwth, cwasher, dbt1, dbt99, dishwash, dntheat, dolelahucol, dolelahuheat, dolelcdr, dolelcfan, dolelcok, dolelcol, dolelcw, doleldhum, doleldwh, dolelevapcol, dolelfrz, dolelhtbheat, dolelhtbpmp, dolelhum, dolellgt, dolelmicro, dolelnec, dolelplpmp, dolelrfg, dolelrfg1, dolelrfg2, dolelsph, doleltv1, doleltv2, doleltvrel, dolelwth, dolfonec, dolfosph, dolfowth, dollarel, dollarfo, dollarlp, dollarng, dollpcdr, dollpcok, dollpnec, dollpsph, dollpwth, dolngcdr, dolngcok, dolnghtbheat, dolngnec, dolngplheat, dolngsph, dolngwth, door1sum, drafty, dryer, dryrfuel, dryruse, dualcooktfuel, dualovenfuel, dvd, dwashuse, dwcycle, eelights, elcool, elfood, elother, elperiph, elwarm, elwater, energyasst, energyasst11, energyasst12, energyasst13, energyasst14, energyasst15, energyasstoth, equipage, equipaux, equipauxtype, equipm, equipmuse, escwash, esdishw, esdryer, esfreeze, esfrig, eslight, eswater, eswin, foodproc, foother, fopay, fowarm, fowater, freeaudit, fuelaux, fuelh2o, fuelh2o2, fuelpool, fueltub, gallonfo, gallonfonec, gallonfosph, gallonfowth, gallonlp, gallonlpcdr, gallonlpcok, gallonlpnec, gallonlpsph, gallonlpwth, gargcool, gargheat, gndhdd65, gwt, h2oheatapt, hdd30yr, hdd50, hdd65, heathome, highceil, hotma, ice, intdata, intdataacc, intstream, inwireless, kwh, kwhahucol, kwhahuheat, kwhcdr, kwhcfan, kwhcok, kwhcol, kwhcw, kwhdhum, kwhdwh, kwhevapcol, kwhfrz, kwhhtbheat, kwhhtbpmp, kwhhum, kwhlgt, kwhmicro, kwhnec, kwhplpmp, kwhrfg, kwhrfg1, kwhrfg2, kwhsph, kwhtv1, kwhtv2, kwhtvrel, kwhwth, lgtin4, lgtincan, lgtincfl, lgtincntl, lgtinled, lgtinnum, lgtoutcntl, lgtoutnum, locrfri2, lpcook, lpgpay, lpother, lpwarm, lpwater, micro, moisture, monpool, montub, morethan1h2o, ncombath, nhafbath, noacbroke, noacdays, noacel, noachelp, noheatbroke, noheatbulk, noheatdays, noheatel, noheathelp, noheatng, notmoist, numatticfan, numberac, numcfan, numfloorfan, numfreez, nummeal, numsmphone, numwholefan, oa_lat, othrooms, outgrill, outgrillfuel, outlet, oven, ovenfuel, ovenuse, payhelp, pelletamt, pelletbtu, periodel, periodfo, periodlp, periodng, playsta, pool, prkgplc1, protherm, prothermac, rebateapp, recbath, recycapp, ricecook, rooftype, scaleb, scalee, scaleg, sepcooktuse, sepdvr, sepovenuse, sizeofgarage, sizfreez, sizrfri1, sizrfri2, smartmeter, smarttherm, solar, solother, solwater, stories, stove, stovefuel, stovenfuel, studio, swampcol, swimpool, taxcreditapp, tempgone, tempgoneac, temphome, temphomeac, tempnite, tempniteac, thermain, thermainac, toast, toastovn, topfront, totalbtu, totalbtucdr, totalbtucok, totalbtuhtb, totalbtunec, totalbtupl, totalbtusph, totalbtuwth, totaldol, totaldolcdr, totaldolcok, totaldolhtb, totaldolnec, totaldolpl, totaldolsph, totaldolwth, totcsqft, tothsqft, totsqft_en, totucsqft, totusqft, tvaudiosys, tvcolor, tvonwd1, tvonwd2, tvonwe1, tvonwe2, tvsize1, tvsize2, tvtype1, tvtype2, typeglass, typerfr1, typerfr2, ugashere, ugcook, ugoth, ugwarm, ugwater, uprtfrzr, usecenac, useel, usefo, uselp, usemoisture, useng, usenotmoist, usesolar, usewood, usewwac, vcr, walltype, washload, wdother, wdpellet, wdwarm, wdwater, wheatage, wheatsiz, windows, winframe, woodamt, woodbtu, woodlogs, wsf, wwacage  Applying integer scaling to spatial predictor variables... Merging donor spatial predictor variables... Merging recipient spatial predictor variables... Assembling output data frames... Performing consistency checks... lapply(data, dim) $RECS_2015 [1] 5686  649  $ACS_2015 [1] 1226728     242 v <- names(data$ACS_2015)[2:6] head(data$RECS_2015[v]) weight bedrooms__bdsp desktop__laptop education__schl elpay__elefp 1  10855              3               2               2            2 2  13165              2               1               2            2 3  22095              4               2               1            2 4  10935              3               2               4            2 5  15485              3               2               2            2 6  24825              0               2               1            1 head(data$ACS_2015[v]) weight bedrooms__bdsp desktop__laptop education__schl elpay__elefp 1    110              5               2               4            2 2     91              4               2               5            2 3    112              4               2               2            2 4     80              3               2               3            2 5    156              3               2               3            2 6    100              1               2               4            2 round(table(data$RECS_2015$fuelheat__hfl) / nrow(data[[1]]), 3) 1     2     3     4     5     6     7  0.045 0.347 0.043 0.491 0.042 0.001 0.030 round(table(data$ACS_2015$fuelheat__hfl) / nrow(data[[2]]), 3) 1     2     3     4     5     6     7  0.012 0.364 0.055 0.469 0.064 0.008 0.028 names(data$ACS_2015) [1] \"acs_2015_hid\"            \"weight\"                    [3] \"bedrooms__bdsp\"          \"desktop__laptop\"           [5] \"education__schl\"         \"elpay__elefp\"              [7] \"employhh__wkhp\"          \"fuelheat__hfl\"             [9] \"hhage__agep\"             \"hhsex__sex\"               [11] \"householder_race__rac1p\" \"internet__access\"         [13] \"kownrent__ten\"           \"moneypy__hincp\"           [15] \"ngpay__gasfp\"            \"nhsldmem__np\"             [17] \"numadult__agep\"          \"numchild__agep\"           [19] \"numfrig__refr\"           \"numtablet__handheld\"      [21] \"occupyyrange__mv\"        \"sdescent__hisp\"           [23] \"stoven__stov\"            \"totrooms__rmsp\"           [25] \"typehuq__bld\"            \"yearmaderange__ybl\"       [27] \"loc..ur12\"               \"loc..cbsatype15\"          [29] \"loc..region\"             \"loc..recs_division\"       [31] \"loc..recs_ba_zone\"       \"loc..recs_iecc_zone\"      [33] \"acs.pums..npa\"           \"acs.pums..accssywstsb\"    [35] \"acs.pums..accssywstsc\"   \"acs.pums..acrn\"           [37] \"acs.pums..acrhl\"         \"acs.pums..acrht\"          [39] \"acs.pums..anf1\"          \"acs.pums..agsn\"           [41] \"acs.pums..bthy\"          \"acs.pums..bdsp\"           [43] \"acs.pums..bldm\"          \"acs.pums..bldofhd\"        [45] \"acs.pums..bldofhm\"       \"acs.pums..bld5\"           [47] \"acs.pums..brdy\"          \"acs.pums..bsnf\"           [49] \"acs.pums..bsys\"          \"acs.pums..cmpy\"           [51] \"acs.pums..dlpy\"          \"acs.pums..dsly\"           [53] \"acs.pums..elep\"          \"acs.pums..fbry\"           [55] \"acs.pums..fsys\"          \"acs.pums..flpx\"           [57] \"acs.pums..gspy\"          \"acs.pums..hndy\"           [59] \"acs.pums..hflu\"          \"acs.pums..hfle\"           [61] \"acs.pums..hflf\"          \"acs.pums..insp\"           [63] \"acs.pums..lpty\"          \"acs.pums..mdmy\"           [65] \"acs.pums..mrgnb\"         \"acs.pums..mrgyp\"          [67] \"acs.pums..mrgp\"          \"acs.pums..mrgtn\"          [69] \"acs.pums..mrgty\"         \"acs.pums..mrgxn\"          [71] \"acs.pums..mrgm\"          \"acs.pums..mrgc\"           [73] \"acs.pums..othy\"          \"acs.pums..rfry\"           [75] \"acs.pums..rmsp\"          \"acs.pums..rntn\"           [77] \"acs.pums..rntp\"          \"acs.pums..rwty\"           [79] \"acs.pums..stly\"          \"acs.pums..snky\"           [81] \"acs.pums..stvy\"          \"acs.pums..tlysx\"          [83] \"acs.pums..tnow\"          \"acs.pums..tnof\"           [85] \"acs.pums..tnrn\"          \"acs.pums..tlysb\"          [87] \"acs.pums..vlpc\"          \"acs.pums..vhnv\"           [89] \"acs.pums..vh1v\"          \"acs.pums..vh2v\"           [91] \"acs.pums..vh3v\"          \"acs.pums..wtph\"           [93] \"acs.pums..yb19\"          \"acs.pums..y194\"           [95] \"acs.pums..y195\"          \"acs.pums..y196\"           [97] \"acs.pums..y197\"          \"acs.pums..y198\"           [99] \"acs.pums..y199\"          \"acs.pums..y202\"          [101] \"acs.pums..fsnf\"          \"acs.pums..fsmcfhw\"       [103] \"acs.pums..fsmcfhl\"       \"acs.pums..fsmcfn\"        [105] \"acs.pums..fsof\"          \"acs.pums..fncp\"          [107] \"acs.pums..fprn\"          \"acs.pums..fwr5\"          [109] \"acs.pums..fw51\"          \"acs.pums..fw55\"          [111] \"acs.pums..grnt\"          \"acs.pums..grpp\"          [113] \"acs.pums..hhle\"          \"acs.pums..hhls\"          [115] \"acs.pums..hhtm\"          \"acs.pums..hhto\"          [117] \"acs.pums..hhtnhm\"        \"acs.pums..hhtnhf\"        [119] \"acs.pums..hncp\"          \"acs.pums..hgch\"          [121] \"acs.pums..hwc6\"          \"acs.pums..hw61\"          [123] \"acs.pums..hw66\"          \"acs.pums..hpc6\"          [125] \"acs.pums..hpc61\"         \"acs.pums..hpc661\"        [127] \"acs.pums..hpr6\"          \"acs.pums..hpr61\"         [129] \"acs.pums..hpr661\"        \"acs.pums..ktyh\"          [131] \"acs.pums..lal1\"          \"acs.pums..mltn\"          [133] \"acs.pums..mv1m\"          \"acs.pums..m1t2\"          [135] \"acs.pums..m2t4\"          \"acs.pums..m5t9\"          [137] \"acs.pums..m1t1\"          \"acs.pums..m2t2\"          [139] \"acs.pums..nocc\"          \"acs.pums..npfd\"          [141] \"acs.pums..nppn\"          \"acs.pums..nrnn\"          [143] \"acs.pums..nrcg\"          \"acs.pums..ocpp\"          [145] \"acs.pums..prtn\"          \"acs.pums..plmy\"          [147] \"acs.pums..psfn\"          \"acs.pums..r18n\"          [149] \"acs.pums..r60n\"          \"acs.pums..r601\"          [151] \"acs.pums..r65n\"          \"acs.pums..r651\"          [153] \"acs.pums..rsmm\"          \"acs.pums..rsmc\"          [155] \"acs.pums..smcp\"          \"acs.pums..smxnbb\"        [157] \"acs.pums..smxnob\"        \"acs.pums..ssmh\"          [159] \"acs.pums..txpn\"          \"acs.pums..wfnn\"          [161] \"acs.pums..wfnw\"          \"acs.pums..wf1w\"          [163] \"acs.pums..wf2w\"          \"acs.pums..wkxn\"          [165] \"acs.pums..wkxrlhs\"       \"acs.pums..wkxrlhwftsw\"   [167] \"acs.pums..wkxrlhwftsd\"   \"acs.pums..wkxrlhd\"       [169] \"acs.pums..wkxf\"          \"acs.pums..wrksttnf\"      [171] \"acs.pums..wrkstthw\"      \"acs.pums..wrkstthl\"      [173] \"acs.pums..wrksttnh\"      \"acs.pums..wrkf\"          [175] \"acs.pums..elfv\"          \"acs.pums..flfi\"          [177] \"acs.pums..flfn\"          \"acs.pums..gsfpip\"        [179] \"acs.pums..gsfpir\"        \"acs.pums..gsfn\"          [181] \"acs.pums..wtfi\"          \"acs.pums..wtfn\"          [183] \"acs.sf..b010\"            \"acs.sf..b060\"            [185] \"acs.sf..b080\"            \"acs.sf..b1900\"           [187] \"acs.sf..b1910\"           \"acs.sf..b1920\"           [189] \"acs.sf..b25010\"          \"acs.sf..b250350\"         [191] \"acs.sf..b250390\"         \"acs.sf..b25060\"          [193] \"acs.sf..b250710\"         \"acs.sf..b250770\"         [195] \"acs.sf..b25080\"          \"acs.sf..b25090\"          [197] \"acs.sf..b2510\"           \"climate..cddb6\"          [199] \"climate..hddb6\"          \"climate..cdd12b6\"        [201] \"climate..hdd12b6\"        \"climate..iccz\"           [203] \"climate..bznf\"           \"eia.seds..gslp\"          [205] \"eia.seds..elcp\"          \"eia.seds..ntgp\"          [207] \"eia.seds..lpgp\"          \"eia.seds..fllp\"          [209] \"eia.seds..elmh\"          \"eia.seds..ntth\"          [211] \"eia.seds..lpgh\"          \"eia.seds..flgh\"          [213] \"eia.seds..elce\"          \"eia.seds..ntge\"          [215] \"eia.seds..lpge\"          \"eia.seds..flle\"          [217] \"eia.seds..eleh\"          \"eia.seds..nteh\"          [219] \"eia.seds..lpeh\"          \"eia.seds..fleh\"          [221] \"irs.soi..mipr\"           \"irs.soi..mipp\"           [223] \"irs.soi..mppr\"           \"irs.soi..mdpr\"           [225] \"irs.soi..prsr\"           \"irs.soi..prjr\"           [227] \"irs.soi..phohr\"          \"irs.soi..pppr\"           [229] \"irs.soi..pvpr\"           \"irs.soi..prcntelr\"       [231] \"irs.soi..prfr\"           \"irs.soi..prcntetr\"       [233] \"irs.soi..prie\"           \"irs.soi..priu\"           [235] \"irs.soi..eftr\"           \"irs.soi..palt2\"          [237] \"irs.soi..pa2t5\"          \"irs.soi..pa5t7\"          [239] \"irs.soi..pa7t1\"          \"irs.soi..pa1t2\"          [241] \"irs.soi..pa2om\"          \"nrel.urdb..rsed\" # Prepare RECS 2015 household microdata for fusion with ACS 2015 microdata prep <- prepare(donor = \"RECS_2015\",                  recipient = \"ACS_2015\",                  respondent = \"household\",                 implicates = 5) Harmonizing RECS_2015 (donor) microdata at household level Harmonizing ACS_2015 (recipient) microdata at household level Identified 124 geographic intersections in the donor... Imputing PUMA for donor observations... Assigning location variables to recipient observations... data <- assemble(prep,                  fusion.variables = c(\"cooltype\", \"agecenac\", \"kwhcol\"),                  window = 3,                  pca = c(30, 0.9)) Identifying donor fusion variables... Adding the following fusion variables:  agecenac, cooltype, kwhcol  Performing principal components analysis... Applying integer scaling to spatial predictor variables... Merging donor spatial predictor variables... Merging recipient spatial predictor variables... Assembling output data frames... Performing consistency checks... lapply(data, dim) $RECS_2015 [1] 28430    67  $ACS_2015 [1] 1226728      64 names(data$ACS_2015) [1] \"acs_2015_hid\"            \"weight\"                   [3] \"bedrooms__bdsp\"          \"desktop__laptop\"          [5] \"education__schl\"         \"elpay__elefp\"             [7] \"employhh__wkhp\"          \"fuelheat__hfl\"            [9] \"hhage__agep\"             \"hhsex__sex\"              [11] \"householder_race__rac1p\" \"internet__access\"        [13] \"kownrent__ten\"           \"moneypy__hincp\"          [15] \"ngpay__gasfp\"            \"nhsldmem__np\"            [17] \"numadult__agep\"          \"numchild__agep\"          [19] \"numfrig__refr\"           \"numtablet__handheld\"     [21] \"occupyyrange__mv\"        \"sdescent__hisp\"          [23] \"stoven__stov\"            \"totrooms__rmsp\"          [25] \"typehuq__bld\"            \"yearmaderange__ybl\"      [27] \"loc..ur12\"               \"loc..cbsatype15\"         [29] \"loc..region\"             \"loc..recs_division\"      [31] \"loc..recs_ba_zone\"       \"loc..recs_iecc_zone\"     [33] \"climate..iccz\"           \"climate..bznf\"           [35] \"pca..PC1\"                \"pca..PC2\"                [37] \"pca..PC3\"                \"pca..PC4\"                [39] \"pca..PC5\"                \"pca..PC6\"                [41] \"pca..PC7\"                \"pca..PC8\"                [43] \"pca..PC9\"                \"pca..PC10\"               [45] \"pca..PC11\"               \"pca..PC12\"               [47] \"pca..PC13\"               \"pca..PC14\"               [49] \"pca..PC15\"               \"pca..PC16\"               [51] \"pca..PC17\"               \"pca..PC18\"               [53] \"pca..PC19\"               \"pca..PC20\"               [55] \"pca..PC21\"               \"pca..PC22\"               [57] \"pca..PC23\"               \"pca..PC24\"               [59] \"pca..PC25\"               \"pca..PC26\"               [61] \"pca..PC27\"               \"pca..PC28\"               [63] \"pca..PC29\"               \"pca..PC30\""},{"path":"https://ummel.github.io/fusionData/index.html","id":"make-it-rain","dir":"","previous_headings":"","what":"Make it rain","title":"Data backend for fusionACS platform","text":"point, ready fuse. straightforward using train() fuse() functions fusionModel package.","code":""},{"path":"https://ummel.github.io/fusionData/reference/assemble.html","id":null,"dir":"Reference","previous_headings":"","what":"Assemble data used for survey fusion — assemble","title":"Assemble data used for survey fusion — assemble","text":"Assembles data inputs pass train fuse perform survey fusion. Adds fusion, replicate weight, /spatial variables checks donor recipient output data frames consistent.","code":""},{"path":"https://ummel.github.io/fusionData/reference/assemble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assemble data used for survey fusion — assemble","text":"","code":"assemble(   x,   fusion.variables = NULL,   spatial.datasets = \"all\",   window = 2,   pca = NULL,   replicates = FALSE )"},{"path":"https://ummel.github.io/fusionData/reference/assemble.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assemble data used for survey fusion — assemble","text":"x List object produced prepare. fusion.variables Character. Names donor variables included output fusion candidates. NULL (default), attempt made return donor variables used harmonization process. spatial.datasets Character. Vector requested spatial datasets merge (e.g. \"EPA-SLD\") either two special values: \"\" (default) \"none\". window Integer. Size allowable temporal window, years, merging spatial variables. window = 0 (default) means spatial variable included vintage survey. See Details. pca Numeric. Controls whether/PCA used reduce dimensionality spatial variables. Default (NULL) PCA. non-NULL, numeric vector length two; e.g. pca = c(50, 0.95). First number maximum number components return; second number target proportion variance explained. See Details. replicates Logical. replicate observation weights included, available? Defaults FALSE.","code":""},{"path":"https://ummel.github.io/fusionData/reference/assemble.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assemble data used for survey fusion — assemble","text":"list length two containing donor recipient microdata pass train fuse.","code":""},{"path":"https://ummel.github.io/fusionData/reference/assemble.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Assemble data used for survey fusion — assemble","text":"Spatial variables included associated vintage within +/- window years survey vintage. cases spatial variable multiple vintages equidistant survey vintage, older vintage selected. Variables vintage = \"always\" , course, always included. PCA restricted numeric spatial variables computed using prcomp. returned number principal components lesser pca[1] number components explain least pca[2] proportion variance. example, pca = c(50, 0.95) select fewest number components explain 95% variance, 50 components maximum. NA's numeric spatial variables imputed using median value prior computing principal components.","code":""},{"path":"https://ummel.github.io/fusionData/reference/assemble.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assemble data used for survey fusion — assemble","text":"","code":"prep <- prepare(donor = \"RECS_2015\",                 recipient = \"ACS_2015\",                 respondent = \"household\",                 implicates = 3) #> Warning: cannot open file 'harmony/harmonies/RECS_2015__ACS_2015.R': No such file or directory #> Error in file(filename, \"r\"): cannot open the connection  data <- assemble(x = prep) #> Error in assemble(x = prep): object 'prep' not found"},{"path":"https://ummel.github.io/fusionData/reference/bg_centroids.html","id":null,"dir":"Reference","previous_headings":"","what":"Block group centroids circa 2010 — bg_centroids","title":"Block group centroids circa 2010 — bg_centroids","text":"Population-weighted block group centroids. sf points object. Useful assigning coordinate-based spatial features block groups create geographic concordance; e.g. using st_nearest_feature.","code":""},{"path":"https://ummel.github.io/fusionData/reference/bg_centroids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Block group centroids circa 2010 — bg_centroids","text":"","code":"bg_centroids"},{"path":"https://ummel.github.io/fusionData/reference/bg_centroids.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Block group centroids circa 2010 — bg_centroids","text":"sf spatial data frame. state State code county10 County code tract10 Tract code bg10 Block group code geometry Centroid coordinates `sfc_POINT` class","code":""},{"path":"https://ummel.github.io/fusionData/reference/bg_centroids.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Block group centroids circa 2010 — bg_centroids","text":"https://www2.census.gov/geo/docs/reference/cenpop2010/blkgrp/","code":""},{"path":"https://ummel.github.io/fusionData/reference/compileDictionary.html","id":null,"dir":"Reference","previous_headings":"","what":"Compile universal survey dictionary — compileDictionary","title":"Compile universal survey dictionary — compileDictionary","text":"Compiles individual survey data dictionaries /survey-processed two tibbles saved disk use fusionData package well universe harmony Shiny apps.","code":""},{"path":"https://ummel.github.io/fusionData/reference/compileDictionary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compile universal survey dictionary — compileDictionary","text":"","code":"compileDictionary()"},{"path":"https://ummel.github.io/fusionData/reference/compileDictionary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compile universal survey dictionary — compileDictionary","text":"Saves dictionary.rda surveys.rda data frames disk /data, /universe/www, /harmony/www.","code":""},{"path":"https://ummel.github.io/fusionData/reference/compileDictionary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compile universal survey dictionary — compileDictionary","text":"","code":"compileDictionary() #> Error in mutate(., respondent = ifelse(substring(tolower(respondent),     1, 1) == \"h\", \"Household\", \"Person\")): ℹ In argument: `respondent = ifelse(...)`. #> Caused by error in `tolower()`: #> ! object 'respondent' not found"},{"path":"https://ummel.github.io/fusionData/reference/compileSpatial.html","id":null,"dir":"Reference","previous_headings":"","what":"Compile all spatial predictor variables — compileSpatial","title":"Compile all spatial predictor variables — compileSpatial","text":"Detects compiles processed spatial datasets located /geo-processed single .fst file utilized assemble.","code":""},{"path":"https://ummel.github.io/fusionData/reference/compileSpatial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compile all spatial predictor variables — compileSpatial","text":"","code":"compileSpatial()"},{"path":"https://ummel.github.io/fusionData/reference/compileSpatial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compile all spatial predictor variables — compileSpatial","text":"Saves /geo-processed/geo_predictors.fst disk.","code":""},{"path":"https://ummel.github.io/fusionData/reference/compileSpatial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compile all spatial predictor variables — compileSpatial","text":"","code":"compileSpatial() #> Identified 0 processed.rds files across 0 spatial datasets:   #> Summarizing spatial datasets... #> Error in compileSpatial(): object '..keep' not found"},{"path":"https://ummel.github.io/fusionData/reference/conveyHarmony.html","id":null,"dir":"Reference","previous_headings":"","what":"Convey an existing harmony file to new survey(s) — conveyHarmony","title":"Convey an existing harmony file to new survey(s) — conveyHarmony","text":"Attempts convey harmonies existing harmony file new harmony file different survey(s). useful introducing new vintage existing survey, already-specified harmonies may valid new vintage.","code":""},{"path":"https://ummel.github.io/fusionData/reference/conveyHarmony.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convey an existing harmony file to new survey(s) — conveyHarmony","text":"","code":"conveyHarmony(from, to, overwrite = FALSE)"},{"path":"https://ummel.github.io/fusionData/reference/conveyHarmony.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convey an existing harmony file to new survey(s) — conveyHarmony","text":"Character. Name .R harmony file existing harmonies interest (e.g. \"RECS_2015__ACS_2019.R\") Character. Name desired new harmony file (e.g. \"RECS_2015__ACS_2015.R\"). overwrite Logical. already exists, overwritten? Default FALSE.","code":""},{"path":"https://ummel.github.io/fusionData/reference/conveyHarmony.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convey an existing harmony file to new survey(s) — conveyHarmony","text":"harmony file written disk (/harmony/harmonies), valid harmonies detected. list object retained harmonies written disk using internal function harmony/R/harmony2dotR.R. Possible message printed console indicating harmonies strictly valid explored manually via harmony app.","code":""},{"path":"https://ummel.github.io/fusionData/reference/conveyHarmony.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convey an existing harmony file to new survey(s) — conveyHarmony","text":"harmony considered valid , must match exactly variable names factor levels (present). User always manually check .R file using analysis!","code":""},{"path":"https://ummel.github.io/fusionData/reference/conveyHarmony.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convey an existing harmony file to new survey(s) — conveyHarmony","text":"","code":"conveyHarmony(from = \"RECS_2015__ACS_2019.R\", to = \"RECS_2015__ACS_2015.R\") #> Warning: cannot open file 'harmony/R/harmony2dotR.R': No such file or directory #> Error in file(filename, \"r\", encoding = encoding): cannot open the connection"},{"path":"https://ummel.github.io/fusionData/reference/createDictionary.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate data dictionary from survey microdata — createDictionary","title":"Generate data dictionary from survey microdata — createDictionary","text":"Produces data dictionary standard structure can saved alongside processed microdata. Resulting dictionary can compiled survey dictionaries via compileDictionary. function typically called end .R script generates processed survey microdata.","code":""},{"path":"https://ummel.github.io/fusionData/reference/createDictionary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate data dictionary from survey microdata — createDictionary","text":"","code":"createDictionary(data, survey, vintage, respondent)"},{"path":"https://ummel.github.io/fusionData/reference/createDictionary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate data dictionary from survey microdata — createDictionary","text":"data Data frame. Survey microdata variable descriptions stored columns via var_label. survey Character. Unique survey identifier (e.g. \"RECS\"). vintage Character. Survey vintage (e.g. 2015). respondent Character. Respondent type; either \"Household\" \"Person\" string identifiable .","code":""},{"path":"https://ummel.github.io/fusionData/reference/createDictionary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate data dictionary from survey microdata — createDictionary","text":"Returns tibble standard \"dictionary\" information based provided microdata.","code":""},{"path":"https://ummel.github.io/fusionData/reference/fusionData-package.html","id":null,"dir":"Reference","previous_headings":"","what":"fusionData: Data backend for fusionACS platform — fusionData-package","title":"fusionData: Data backend for fusionACS platform — fusionData-package","text":"Pre-process raw survey spatial data. Harmonize variables across surveys. Build harmonized microdata use fusionModel package.","code":""},{"path":"https://ummel.github.io/fusionData/reference/fusionData-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"fusionData: Data backend for fusionACS platform — fusionData-package","text":"Maintainer: Kevin Ummel ummel@sas.upenn.edu","code":""},{"path":"https://ummel.github.io/fusionData/reference/getGeoProcessed.html","id":null,"dir":"Reference","previous_headings":"","what":"Download processed spatial data — getGeoProcessed","title":"Download processed spatial data — getGeoProcessed","text":"Since processed spatial data files generally large upload Github attach fusionData package, stored Google Drive. function downloads requested processed geographic data places appropriate local sub-directory /fusionData/geo_processed. full file path (e.g. intermediate directories) created, necessary, existing data disk altered deleted.","code":""},{"path":"https://ummel.github.io/fusionData/reference/getGeoProcessed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download processed spatial data — getGeoProcessed","text":"","code":"getGeoProcessed(dataset = \"essential\")"},{"path":"https://ummel.github.io/fusionData/reference/getGeoProcessed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download processed spatial data — getGeoProcessed","text":"dataset Character. Indicate spatial dataset(s) download. dataset = \"essential\", files necessary call prepare assemble downloaded. dataset = \"\", processed spatial data files downloaded. Otherwise, single spatial dataset identifier (e.g. \"EPA-SLD\") download associated \"*_processed.rds\" files.","code":""},{"path":"https://ummel.github.io/fusionData/reference/getGeoProcessed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download processed spatial data — getGeoProcessed","text":"drive_download prints messages console indicating files downloaded.","code":""},{"path":"https://ummel.github.io/fusionData/reference/getGeoProcessed.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Download processed spatial data — getGeoProcessed","text":"Files automatically placed appropriate sub-directory fusionData/geo_processed. dataset = \"essential\", downloaded files : \"geo_predictors.fst\" \"concordance/geo_concordance.fst\".","code":""},{"path":"https://ummel.github.io/fusionData/reference/getGeoProcessed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download processed spatial data — getGeoProcessed","text":"","code":"getGeoProcessed(dataset = \"essential\") #> Warning: cannot open compressed file 'data/token.rda', probable reason 'No such file or directory' #> Error in readChar(con, 5L, useBytes = TRUE): cannot open the connection"},{"path":"https://ummel.github.io/fusionData/reference/getSurveyProcessed.html","id":null,"dir":"Reference","previous_headings":"","what":"Download processed survey microdata — getSurveyProcessed","title":"Download processed survey microdata — getSurveyProcessed","text":"Since processed survey microdata files generally large upload Github attach fusionData package, processed microdata (.fst) files stored Google Drive. function downloads requested survey microdata places appropriate local sub-directory /fusionData/survey-processed. full file path (e.g. intermediate directories) created, necessary, existing data disk altered deleted.","code":""},{"path":"https://ummel.github.io/fusionData/reference/getSurveyProcessed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download processed survey microdata — getSurveyProcessed","text":"","code":"getSurveyProcessed(survey)"},{"path":"https://ummel.github.io/fusionData/reference/getSurveyProcessed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download processed survey microdata — getSurveyProcessed","text":"survey Character. Survey identifier, possibly including vintage respondent type. See Details.","code":""},{"path":"https://ummel.github.io/fusionData/reference/getSurveyProcessed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download processed survey microdata — getSurveyProcessed","text":"drive_download prints messages console indicating files downloaded.","code":""},{"path":"https://ummel.github.io/fusionData/reference/getSurveyProcessed.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Download processed survey microdata — getSurveyProcessed","text":"survey must include unique survey identifier. just identifier provided (e.g. survey = \"RECS\"), available processed microdata across vintages respondents downloaded. Alternatively, can specify survey vintage (e.g. survey = \"RECS_2015\") include additional respondent code (e.g. survey = \"RECS_2015_H\") limit download restrictive subsets. special argument survey = \"\" download available processed microdata across surveys.","code":""},{"path":"https://ummel.github.io/fusionData/reference/getSurveyProcessed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download processed survey microdata — getSurveyProcessed","text":"","code":"getSurveyProcessed(survey = \"RECS_2015_H\") #> Warning: cannot open compressed file 'data/token.rda', probable reason 'No such file or directory' #> Error in readChar(con, 5L, useBytes = TRUE): cannot open the connection"},{"path":"https://ummel.github.io/fusionData/reference/harmonize.html","id":null,"dir":"Reference","previous_headings":"","what":"Create harmonized microdata — harmonize","title":"Create harmonized microdata — harmonize","text":"Parses specified .R \"harmony file\" produced Survey Harmonization Tool harmony produce associated microdata available harmonized variables. function called within prepare likely never needs called user directly.","code":""},{"path":"https://ummel.github.io/fusionData/reference/harmonize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create harmonized microdata — harmonize","text":"","code":"harmonize(harmony.file, respondent, output = \"both\")"},{"path":"https://ummel.github.io/fusionData/reference/harmonize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create harmonized microdata — harmonize","text":"harmony.file Character. Name .R harmony file located /harmony/harmonies. respondent Character. output microdata \"household\" \"person\" level? output Character. Can \"\", \"donor\", \"recipient\", indicating microdata return.","code":""},{"path":"https://ummel.github.io/fusionData/reference/harmonize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create harmonized microdata — harmonize","text":"output = \"\", list length 2 containing donor recipient data frames. Otherwise, single data frame.","code":""},{"path":"https://ummel.github.io/fusionData/reference/harmonize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create harmonized microdata — harmonize","text":"","code":"test <- harmonize(harmony.file = \"CEI_2015-2019__ACS_2015.R\", respondent = \"household\") #> Warning: cannot open file 'harmony/harmonies/CEI_2015-2019__ACS_2015.R': No such file or directory #> Error in file(filename, \"r\"): cannot open the connection"},{"path":"https://ummel.github.io/fusionData/reference/harmony.html","id":null,"dir":"Reference","previous_headings":"","what":"Open the fusionACS Survey Harmonization Tool — harmony","title":"Open the fusionACS Survey Harmonization Tool — harmony","text":"Opens 'harmony' Shiny app (/harmony); .e. fusionACS Survey Harmonization Tool.","code":""},{"path":"https://ummel.github.io/fusionData/reference/harmony.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Open the fusionACS Survey Harmonization Tool — harmony","text":"","code":"harmony()"},{"path":"https://ummel.github.io/fusionData/reference/harmony.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Open the fusionACS Survey Harmonization Tool — harmony","text":"Opens app new browser window. R session occupied window open.","code":""},{"path":"https://ummel.github.io/fusionData/reference/harmony.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Open the fusionACS Survey Harmonization Tool — harmony","text":"","code":"harmony() #> Error in shinyAppDir(x): No Shiny application exists at the path \"harmony\""},{"path":"https://ummel.github.io/fusionData/reference/prepare.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare microdata inputs for assembly — prepare","title":"Prepare microdata inputs for assembly — prepare","text":"Prepares data inputs pass assemble. Harmonizes common variables specified donor recipient surveys, imputes PUMA donor records, samples location variables recipient records.","code":""},{"path":"https://ummel.github.io/fusionData/reference/prepare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare microdata inputs for assembly — prepare","text":"","code":"prepare(donor, recipient, respondent, implicates = 1, collapse = FALSE)"},{"path":"https://ummel.github.io/fusionData/reference/prepare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare microdata inputs for assembly — prepare","text":"donor Character. Donor survey identifier (e.g. \"RECS_2015\"). recipient Character. Recipient (ACS) survey identifier (e.g. \"ACS_2019\"). respondent Character. Desired respondent level microdata. Either \"household\" \"person\". implicates Integer. Number PUMA implicates return donor microdata. collapse Logical. rows collapsed weighting factors aggregated multiple imputations household-PUMA?","code":""},{"path":"https://ummel.github.io/fusionData/reference/prepare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare microdata inputs for assembly — prepare","text":"list length two containing output data frames specific donor recipient output, respectfully. Can passed assemble.","code":""},{"path":"https://ummel.github.io/fusionData/reference/prepare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare microdata inputs for assembly — prepare","text":"","code":"prep <- prepare(donor = \"RECS_2015\",                 recipient = \"ACS_2015\",                 respondent = \"household\",                 implicates = 3) #> Warning: cannot open file 'harmony/harmonies/RECS_2015__ACS_2015.R': No such file or directory #> Error in file(filename, \"r\"): cannot open the connection"},{"path":"https://ummel.github.io/fusionData/reference/universe.html","id":null,"dir":"Reference","previous_headings":"","what":"Open the fusionACS Universal Survey Dictionary — universe","title":"Open the fusionACS Universal Survey Dictionary — universe","text":"Opens 'universe' Shiny app (/universe); .e. fusionACS Universal Survey Dictionary.","code":""},{"path":"https://ummel.github.io/fusionData/reference/universe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Open the fusionACS Universal Survey Dictionary — universe","text":"","code":"universe()"},{"path":"https://ummel.github.io/fusionData/reference/universe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Open the fusionACS Universal Survey Dictionary — universe","text":"Opens app new browser window. R session occupied window open.","code":""},{"path":"https://ummel.github.io/fusionData/reference/universe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Open the fusionACS Universal Survey Dictionary — universe","text":"","code":"universe() #> Error in shinyAppDir(x): No Shiny application exists at the path \"universe\""}]
